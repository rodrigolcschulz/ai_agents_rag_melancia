from langchain_chroma import Chroma  # Importa√ß√£o atualizada
from langchain_openai import OpenAIEmbeddings  # Importa√ß√£o atualizada
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import TextLoader, DirectoryLoader
from langchain.schema import Document  # Importar Document para criar documentos corretamente
from .config import EMBEDDING_MODEL
from .keywords import CONTEXT_KEYWORDS
import glob
import os

def carregar_markdowns(markdown_path):
    arquivos = glob.glob(markdown_path, recursive=True)
    docs = []
    for file in arquivos:
        with open(file, "r", encoding="utf-8") as f:
            texto = f.read()
            docs.append({"text": texto, "source": file})
    return docs

def indexar_novos_markdowns(docs, persist_directory, model_name=EMBEDDING_MODEL):
    # Verificar se o modelo √© v√°lido para embeddings
    valid_embedding_models = [
        "text-embedding-ada-002", 
        "text-embedding-3-small", 
        "text-embedding-3-large"
    ]
    
    # Se o modelo n√£o for v√°lido para embeddings, usar o padr√£o
    if model_name not in valid_embedding_models:
        print(f"Aviso: {model_name} n√£o √© um modelo de embedding v√°lido. Usando text-embedding-ada-002")
        model_name = "text-embedding-ada-002"
    
    # Configurar splitter com separadores mais adequados para markdown
    # Prioriza quebras de se√ß√£o (##), depois par√°grafos, depois linhas
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,  # Aumentado para capturar mais contexto
        chunk_overlap=200,  # Aumentado overlap para manter continuidade
        separators=[
            "\n## ",  # Se√ß√µes de markdown
            "\n### ",  # Subse√ß√µes
            "\n\n",  # Par√°grafos
            "\n",  # Linhas
            ". ",  # Senten√ßas
            " ",  # Palavras
            ""  # Caracteres
        ],
        length_function=len,
        is_separator_regex=False
    )
    
    # Criar documentos Document corretamente com metadados
    documentos = []
    for doc in docs:
        documentos.append(Document(
            page_content=doc["text"],
            metadata={"source": doc["source"]}
        ))
    
    # Dividir os documentos em chunks
    textos = splitter.split_documents(documentos)
    
    print(f"   üìÑ Total de chunks criados: {len(textos)}")
    
    # Criar embeddings com o modelo correto
    embeddings = OpenAIEmbeddings(model=model_name)
    
    # Criar o banco vetorial
    db = Chroma.from_documents(textos, embeddings, persist_directory=persist_directory)
    
    # N√£o precisa mais do persist() - √© autom√°tico no Chroma moderno
    # try:
    #     db.persist()
    # except AttributeError:
    #     # Vers√µes mais novas do Chroma persistem automaticamente
    #     pass
    
    return db

def carregar_db_existente(persist_directory, model_name=EMBEDDING_MODEL):
    """Carrega um banco de dados Chroma existente"""
    # Verificar se o modelo √© v√°lido para embeddings
    valid_embedding_models = [
        "text-embedding-ada-002", 
        "text-embedding-3-small", 
        "text-embedding-3-large"
    ]
    
    if model_name not in valid_embedding_models:
        model_name = "text-embedding-ada-002"
    
    embeddings = OpenAIEmbeddings(model=model_name)
    db = Chroma(persist_directory=persist_directory, embedding_function=embeddings)
    return db

def get_retriever(persist_directory, model_name=EMBEDDING_MODEL, k=6):
    """Cria um retriever a partir do banco de dados existente"""
    db = carregar_db_existente(persist_directory, model_name)
    return db.as_retriever(search_kwargs={"k": k})
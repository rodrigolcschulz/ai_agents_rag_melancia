#!/usr/bin/env python3
"""
Teste end-to-end do agente com as perguntas problem√°ticas do usu√°rio
"""
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

from langchain_openai import ChatOpenAI
from langchain.chains import ConversationalRetrievalChain
from src.agent import config
from src.agent.prompt import get_prompt_template
from src.agent.memory import get_memory
from src.agent.retriever import carregar_markdowns, get_retriever, indexar_novos_markdowns


def test_agent_queries():
    """Testa o agente com queries problem√°ticas"""
    
    print("="*80)
    print("ü§ñ TESTE END-TO-END DO AGENTE")
    print("="*80 + "\n")
    
    # 1. Setup RAG
    print("‚öôÔ∏è  Configurando RAG...")
    docs = carregar_markdowns(config.INPUT_MARKDOWN)
    indexar_novos_markdowns(docs, str(config.VECTOR_DB_DIR), config.EMBEDDING_MODEL)
    retriever = get_retriever(str(config.VECTOR_DB_DIR), config.EMBEDDING_MODEL, k=4)
    print(f"   ‚úÖ {len(docs)} documentos indexados\n")
    
    # 2. Setup LLM e Chain
    print("üß† Configurando LLM...")
    llm = ChatOpenAI(
        model=config.MODEL_NAME,
        temperature=config.TEMPERATURE,
        api_key=config.OPENAI_API_KEY,
        max_tokens=1000
    )
    
    memory = get_memory(":memory:")  # Usar mem√≥ria em RAM para teste
    
    qa_chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=retriever,
        memory=memory,
        combine_docs_chain_kwargs={
            "prompt": get_prompt_template(),
            "document_separator": "\n\n---\n\n"
        },
        return_source_documents=True,
        verbose=True  # Para ver o que est√° acontecendo
    )
    print("   ‚úÖ Chain configurada\n")
    
    # 3. Testar queries problem√°ticas
    test_queries = [
        "como proteger a conta no mercado livre?",
        "vc n√£o saberia responder sobre manter a conta no mercado livre segura? protegida?"
    ]
    
    print("="*80)
    print("üí¨ TESTANDO QUERIES")
    print("="*80 + "\n")
    
    for i, query in enumerate(test_queries, 1):
        print(f"\n{'='*80}")
        print(f"Query {i}: {query}")
        print("="*80)
        
        # Invocar chain
        resultado = qa_chain.invoke({"question": query})
        
        # Extrair resposta e documentos
        resposta = resultado.get('answer', 'N/A')
        docs_retrieved = resultado.get('source_documents', [])
        
        print(f"\nüìÑ Documentos recuperados: {len(docs_retrieved)}")
        for j, doc in enumerate(docs_retrieved, 1):
            source = Path(doc.metadata.get('source', 'N/A')).name
            content_preview = doc.page_content[:100].replace('\n', ' ')
            print(f"   {j}. {source}")
            print(f"      {content_preview}...")
        
        print(f"\nüí¨ Resposta do agente:")
        print(f"   {resposta}\n")
        
        # An√°lise
        if "n√£o encontrei" in resposta.lower() or "n√£o tenho" in resposta.lower():
            print("   ‚ö†Ô∏è  PROBLEMA: Agente diz que n√£o encontrou a informa√ß√£o!")
        else:
            print("   ‚úÖ OK: Agente respondeu com informa√ß√µes")
    
    print("\n" + "="*80)
    print("‚úÖ Teste conclu√≠do!")
    print("="*80)


if __name__ == "__main__":
    test_agent_queries()

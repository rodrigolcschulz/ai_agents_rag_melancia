{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“Š PreparaÃ§Ã£o de Dados para Fine-Tuning\n",
    "\n",
    "Transforma seus **103 markdowns** em dataset para fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from src.finetuning.data_prep import DatasetPreparator, format_instruction_dataset\n",
    "from pathlib import Path\n",
    "import re\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ ConfiguraÃ§Ã£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Seus markdowns: ../data/input\n",
      "ğŸ“Š Total: 107 arquivos\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = Path(\"../data/finetuning\")\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PROCESSED_DATA_DIR = DATA_DIR / \"processed\"\n",
    "PROCESSED_DATA_DIR.mkdir(exist_ok=True)\n",
    "MARKDOWN_DIR = Path(\"../data/input\")\n",
    "\n",
    "print(f\"ğŸ“ Seus markdowns: {MARKDOWN_DIR}\")\n",
    "print(f\"ğŸ“Š Total: {len(list(MARKDOWN_DIR.glob('*.md')))} arquivos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Extrair Q&A dos Markdowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Processando seus markdowns...\n",
      "\n",
      "âœ… ExtraÃ­dos 107 pares Q&A!\n",
      "\n",
      "ğŸ“ Primeiro exemplo:\n",
      "Pergunta: 5 Tipos de anÃºncios no Mercado Livre: Guia Completo!?\n",
      "Resposta: Se vocÃª vende no Mercado Livre, Ã© importante conhecer os tipos de anÃºncios disponÃ­veis e suas caracterÃ­sticas. Cada tipo possui vantagens e desvantagens, por isso, Ã© importante saber qual opÃ§Ã£o vale m...\n"
     ]
    }
   ],
   "source": [
    "def extract_qa_from_markdowns(markdown_dir):\n",
    "    \"\"\"Extrai Q&A dos markdowns.\"\"\"\n",
    "    qa_pairs = []\n",
    "    \n",
    "    for md_file in Path(markdown_dir).glob(\"*.md\"):\n",
    "        try:\n",
    "            with open(md_file, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "            \n",
    "            # Pegar tÃ­tulo (linha com #)\n",
    "            lines = content.split('\\n')\n",
    "            title = None\n",
    "            for line in lines:\n",
    "                if line.startswith('# '):\n",
    "                    title = line.replace('# ', '').strip()\n",
    "                    break\n",
    "            \n",
    "            if not title:\n",
    "                title = md_file.stem\n",
    "            \n",
    "            # Remover metadados do final (---)\n",
    "            if '---' in content:\n",
    "                content = content.split('---')[0]\n",
    "            \n",
    "            # Limpar markdown (negrito, itÃ¡lico, links)\n",
    "            content_clean = content\n",
    "            content_clean = re.sub(r'\\*\\*(.+?)\\*\\*', r'\\1', content_clean)\n",
    "            content_clean = re.sub(r'\\*(.+?)\\*', r'\\1', content_clean)\n",
    "            content_clean = re.sub(r'\\[(.+?)\\]\\(.+?\\)', r'\\1', content_clean)\n",
    "            \n",
    "            # Encontrar seÃ§Ãµes com ##\n",
    "            sections = []\n",
    "            current_section = None\n",
    "            current_content = []\n",
    "            \n",
    "            for line in content_clean.split('\\n'):\n",
    "                if line.startswith('## '):\n",
    "                    if current_section:\n",
    "                        sections.append((current_section, '\\n'.join(current_content)))\n",
    "                    current_section = line.replace('## ', '').strip()\n",
    "                    current_content = []\n",
    "                elif current_section:\n",
    "                    current_content.append(line)\n",
    "            \n",
    "            if current_section:\n",
    "                sections.append((current_section, '\\n'.join(current_content)))\n",
    "            \n",
    "            # Se tem seÃ§Ãµes, criar Q&A de cada seÃ§Ã£o\n",
    "            if sections:\n",
    "                for section_title, section_content in sections:\n",
    "                    clean_content = section_content.strip()\n",
    "                    if len(clean_content) > 100:\n",
    "                        # Limitar tamanho\n",
    "                        answer = clean_content[:1000] if len(clean_content) > 1000 else clean_content\n",
    "                        qa_pairs.append({\n",
    "                            \"instruction\": section_title + '?',\n",
    "                            \"output\": answer.strip()\n",
    "                        })\n",
    "            \n",
    "            # Sempre criar uma pergunta geral sobre o documento\n",
    "            paragraphs = [p.strip() for p in content_clean.split('\\n\\n') if len(p.strip()) > 100]\n",
    "            if paragraphs:\n",
    "                # Pegar primeiros 2-3 parÃ¡grafos\n",
    "                intro = '\\n\\n'.join(paragraphs[:2])\n",
    "                if len(intro) > 100:\n",
    "                    answer = intro[:1200] if len(intro) > 1200 else intro\n",
    "                    qa_pairs.append({\n",
    "                        \"instruction\": title + '?',\n",
    "                        \"output\": answer.strip()\n",
    "                    })\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao processar {md_file.name}: {e}\")\n",
    "    \n",
    "    return qa_pairs\n",
    "\n",
    "print(\"ğŸ”„ Processando seus markdowns...\")\n",
    "qa_pairs = extract_qa_from_markdowns(MARKDOWN_DIR)\n",
    "print(f\"\\nâœ… ExtraÃ­dos {len(qa_pairs)} pares Q&A!\")\n",
    "\n",
    "if qa_pairs:\n",
    "    print(f\"\\nğŸ“ Primeiro exemplo:\")\n",
    "    print(f\"Pergunta: {qa_pairs[0]['instruction']}\")\n",
    "    print(f\"Resposta: {qa_pairs[0]['output'][:200]}...\")\n",
    "else:\n",
    "    print(\"âš ï¸ Nenhum Q&A extraÃ­do. Verifique os arquivos markdown.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”„ Formatar Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš ï¸ DIAGNÃ“STICO: Tamanho do Dataset\n",
    "\n",
    "**IMPORTANTE**: VocÃª vai precisar de pelo menos **500-1000 exemplos** para fine-tuning efetivo.\n",
    "\n",
    "Com 107 markdowns, vocÃª vai gerar aproximadamente **~100-200 pares Q&A**.\n",
    "\n",
    "Isso Ã© **MUITO POUCO** e pode causar:\n",
    "- âŒ Catastrophic forgetting (modelo esquece conhecimento geral)\n",
    "- âŒ Overfitting extremo (decora os exemplos)\n",
    "- âŒ Respostas sem sentido durante inferÃªncia\n",
    "\n",
    "**RecomendaÃ§Ã£o**: Use RAG sem fine-tuning. Veja `docs/FINE_TUNING_VS_RAG.md`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset formatado com 107 exemplos!\n",
      "\n",
      "ğŸ“ Exemplo formatado:\n",
      "================================================================================\n",
      "### Instruction:\n",
      "5 Tipos de anÃºncios no Mercado Livre: Guia Completo!?\n",
      "\n",
      "### Response:\n",
      "Se vocÃª vende no Mercado Livre, Ã© importante conhecer os tipos de anÃºncios disponÃ­veis e suas caracterÃ­sticas. Cada tipo possui vantagens e desvantagens, por isso, Ã© importante saber qual opÃ§Ã£o vale mais a pena para as suas vendas. VocÃª sabia que existem 5 tipos de anÃºncios no Mercado Livre? No artigo de hoje, nosso CEO e consultor certificado Joel Jonathan Cunha vai lhe apresentar em detalhes quais sÃ£o e como ...\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "if not qa_pairs:\n",
    "    raise ValueError(\"âŒ Nenhum dado foi extraÃ­do! Verifique os markdowns.\")\n",
    "\n",
    "dataset = format_instruction_dataset(qa_pairs, template=\"alpaca\")\n",
    "print(f\"âœ… Dataset formatado com {len(dataset)} exemplos!\")\n",
    "print(f\"\\nğŸ“ Exemplo formatado:\")\n",
    "print(\"=\" * 80)\n",
    "print(dataset[0]['text'][:500] + \"...\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”€ Dividir Treino/ValidaÃ§Ã£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Dataset dividido:\n",
      "   Treino: 96 exemplos\n",
      "   ValidaÃ§Ã£o: 11 exemplos\n"
     ]
    }
   ],
   "source": [
    "preparator = DatasetPreparator(template=\"alpaca\")\n",
    "split_dataset = preparator.create_train_test_split(dataset, test_size=0.1, seed=42)\n",
    "print(f\"ğŸ“Š Dataset dividido:\")\n",
    "print(f\"   Treino: {len(split_dataset['train'])} exemplos\")\n",
    "print(f\"   ValidaÃ§Ã£o: {len(split_dataset['test'])} exemplos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… Validar Qualidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š EstatÃ­sticas:\n",
      "   Total: 96 exemplos\n",
      "   Tamanho mÃ©dio: 1302 caracteres\n",
      "   MÃ­nimo: 1271 | MÃ¡ximo: 1338\n",
      "\n",
      "ğŸ“ 3 exemplos do treino:\n",
      "\n",
      "1. ### Instruction:\n",
      "AnÃºncio patrocinado no Mercado Livre: tudo que vocÃª precisa saber para aumentar as suas vendas.?\n",
      "\n",
      "### Response:\n",
      "Para aumentar a visibilidade e a exposiÃ§Ã£o dos seus produtos no Mercado Livre vocÃª precisarÃ¡ adotar estratÃ©gias que nÃ£o d...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "2. ### Instruction:\n",
      "Ficha TÃ©cnica nos AnÃºncios do Mercado Livre: nÃ£o deixe em branco!?\n",
      "\n",
      "### Response:\n",
      "Ao contrÃ¡rio do que alguns vendedores podem pensar, aficha tÃ©cnica nos anÃºncios do Mercado LivreÃ© muito importante para aumentar as vendas. AlÃ©m de aju...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "3. ### Instruction:\n",
      "Ruptura de estoque nos anÃºncios do Mercado Livre: nÃ£o deixe isso acontecer!?\n",
      "\n",
      "### Response:\n",
      "A gestÃ£o eficiente do estoque Ã© um dos pilares para o sucesso das vendas on-line. Por isso, os vendedores devem evitar que ocorra a ruptura d...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "texts = [item['text'] for item in split_dataset['train']]\n",
    "lengths = [len(text) for text in texts]\n",
    "\n",
    "print(\"ğŸ“Š EstatÃ­sticas:\")\n",
    "print(f\"   Total: {len(texts)} exemplos\")\n",
    "print(f\"   Tamanho mÃ©dio: {sum(lengths) / len(lengths):.0f} caracteres\")\n",
    "print(f\"   MÃ­nimo: {min(lengths)} | MÃ¡ximo: {max(lengths)}\")\n",
    "\n",
    "print(f\"\\nğŸ“ 3 exemplos do treino:\")\n",
    "for i in range(min(3, len(split_dataset['train']))):\n",
    "    print(f\"\\n{i+1}. {split_dataset['train'][i]['text'][:250]}...\\n{'-'*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¾ Salvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ DIAGNÃ“STICO FINAL\n",
    "train_size = len(split_dataset['train'])\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ“Š DIAGNÃ“STICO FINAL DO DATASET\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nğŸ“ˆ Tamanho atual:\")\n",
    "print(f\"   â€¢ Treino: {train_size} exemplos\")\n",
    "print(f\"   â€¢ ValidaÃ§Ã£o: {len(split_dataset['test'])} exemplos\")\n",
    "print(f\"   â€¢ Total: {train_size + len(split_dataset['test'])} exemplos\")\n",
    "\n",
    "print(f\"\\nğŸ¯ RecomendaÃ§Ãµes para fine-tuning:\")\n",
    "print(f\"   â€¢ MÃ­nimo viÃ¡vel: 500 exemplos\")\n",
    "print(f\"   â€¢ Recomendado: 1000-2000 exemplos\")\n",
    "print(f\"   â€¢ Ideal: 5000+ exemplos\")\n",
    "\n",
    "if train_size < 500:\n",
    "    print(f\"\\nâš ï¸  STATUS: DATASET MUITO PEQUENO\")\n",
    "    print(f\"   VocÃª tem apenas {(train_size/500)*100:.1f}% do mÃ­nimo recomendado\")\n",
    "    print(f\"\\nâŒ Fazer fine-tuning agora vai resultar em:\")\n",
    "    print(f\"   â€¢ Respostas sem sentido\")\n",
    "    print(f\"   â€¢ AlucinaÃ§Ãµes (tÃ³picos aleatÃ³rios)\")\n",
    "    print(f\"   â€¢ Perda de conhecimento geral\")\n",
    "    print(f\"   â€¢ Overfitting extremo\")\n",
    "    \n",
    "    print(f\"\\nâœ… RECOMENDAÃ‡Ã•ES:\")\n",
    "    print(f\"\\n   1ï¸âƒ£  USE RAG SEM FINE-TUNING (MELHOR OPÃ‡ÃƒO)\")\n",
    "    print(f\"       â†’ Seu RAG jÃ¡ funciona bem\")\n",
    "    print(f\"       â†’ {train_size + len(split_dataset['test'])} markdowns sÃ£o suficientes para RAG\")\n",
    "    print(f\"       â†’ Sem risco de catastrophic forgetting\")\n",
    "    \n",
    "    print(f\"\\n   2ï¸âƒ£  Aumente o dataset antes de fazer fine-tuning:\")\n",
    "    print(f\"       â†’ Data augmentation com GPT-4\")\n",
    "    print(f\"       â†’ Colete logs de perguntas reais\")\n",
    "    print(f\"       â†’ Extraia mais Q&A dos markdowns\")\n",
    "    print(f\"       â†’ Crie variaÃ§Ãµes das perguntas\")\n",
    "    \n",
    "    print(f\"\\n   3ï¸âƒ£  Leia a documentaÃ§Ã£o:\")\n",
    "    print(f\"       â†’ docs/FINE_TUNING_VS_RAG.md\")\n",
    "    print(f\"       â†’ Explica quando usar cada abordagem\")\n",
    "    \n",
    "elif train_size < 1000:\n",
    "    print(f\"\\nâš ï¸  STATUS: DATASET PEQUENO\")\n",
    "    print(f\"   Pode funcionar, mas ainda hÃ¡ risco de overfitting\")\n",
    "    print(f\"   Considere aumentar para 1000+ exemplos\")\n",
    "else:\n",
    "    print(f\"\\nâœ… STATUS: DATASET ADEQUADO\")\n",
    "    print(f\"   Tamanho suficiente para fine-tuning\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"ğŸ’¡ LEMBRE-SE: Para seu caso especÃ­fico (Retail Media),\")\n",
    "print(f\"   RAG provavelmente vai dar melhores resultados que fine-tuning!\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf73956cf644e96bed4779b6647bd18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/96 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f9a582a3824159add141bc0b7d012a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/11 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset salvo em: ../data/finetuning/processed/training_dataset\n",
      "âœ… Salvo em: ../data/finetuning/processed/training_dataset\n"
     ]
    }
   ],
   "source": [
    "output_path = PROCESSED_DATA_DIR / \"training_dataset\"\n",
    "preparator.save_dataset(split_dataset, output_path)\n",
    "print(f\"âœ… Salvo em: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Comprimir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ZIP criado: ../data/finetuning/processed/training_dataset.zip\n",
      "ğŸ“¦ Tamanho: 0.04 MB\n",
      "\n",
      "ğŸš€ PrÃ³ximo passo:\n",
      "   1. FaÃ§a upload para Google Drive\n",
      "   2. Use: fine_tuning_qlora_colab.ipynb\n"
     ]
    }
   ],
   "source": [
    "output_zip = PROCESSED_DATA_DIR / \"training_dataset.zip\"\n",
    "shutil.make_archive(str(output_zip.with_suffix('')), 'zip', output_path)\n",
    "print(f\"âœ… ZIP criado: {output_zip}\")\n",
    "print(f\"ğŸ“¦ Tamanho: {output_zip.stat().st_size / 1024 / 1024:.2f} MB\")\n",
    "print(f\"\\nğŸš€ PrÃ³ximo passo:\")\n",
    "print(f\"   1. FaÃ§a upload para Google Drive\")\n",
    "print(f\"   2. Use: fine_tuning_qlora_colab.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

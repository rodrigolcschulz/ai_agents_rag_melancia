# ğŸ§ª Guia de ExperimentaÃ§Ã£o com LLMs

Este guia detalha como experimentar com diferentes modelos de linguagem no MelÃ¢ncIA.

## ğŸ“‹ Ãndice

1. [Setup Inicial](#setup-inicial)
2. [Provedores de LLM](#provedores-de-llm)
3. [Executando Benchmarks](#executando-benchmarks)
4. [AnÃ¡lise de Resultados](#anÃ¡lise-de-resultados)
5. [MLflow Tracking](#mlflow-tracking)
6. [PrÃ³ximos Passos](#prÃ³ximos-passos)

## ğŸš€ Setup Inicial

### 1. Instalar DependÃªncias

```bash
# Instalar todas as dependÃªncias
pip install -r requirements.txt

# Ou apenas experimentaÃ§Ã£o
pip install mlflow transformers torch ollama langchain-ollama
```

### 2. Configurar Provedores

#### OpenAI (PadrÃ£o)

```bash
# Adicionar API key no .env
echo "OPENAI_API_KEY=sk-..." >> .env
```

#### Ollama (Local - Recomendado)

```bash
# Linux/Mac
curl -fsSL https://ollama.ai/install.sh | sh

# Windows
# Baixe de: https://ollama.ai/download

# Baixar modelos
ollama pull llama3.1:8b
ollama pull mistral:7b
ollama pull phi3:mini

# Verificar instalaÃ§Ã£o
ollama list
```

#### HuggingFace (Opcional)

```bash
# Criar token em: https://huggingface.co/settings/tokens
echo "HUGGINGFACE_API_TOKEN=hf_..." >> .env
```

## ğŸ¤– Provedores de LLM

### OpenAI

**PrÃ³s:**
- âœ… Alta qualidade
- âœ… RÃ¡pido
- âœ… Sempre disponÃ­vel

**Contras:**
- âŒ Custo por request
- âŒ Requer internet
- âŒ Limites de rate

**Modelos:**
- `gpt-4o-mini` - Melhor custo-benefÃ­cio (~$0.15/1M tokens)
- `gpt-4o` - MÃ¡xima qualidade (~$5/1M tokens)
- `gpt-3.5-turbo` - Mais barato (~$0.50/1M tokens)

### Ollama (Local)

**PrÃ³s:**
- âœ… Gratuito
- âœ… Privacidade total
- âœ… Sem limites
- âœ… Offline

**Contras:**
- âŒ Requer GPU/RAM
- âŒ Setup inicial
- âŒ Qualidade varia

**Modelos Recomendados:**

| Modelo | Tamanho | RAM | Qualidade | Velocidade |
|--------|---------|-----|-----------|------------|
| `phi3:mini` | 3.8GB | 8GB | Boa | RÃ¡pido |
| `llama3.1:8b` | 4.7GB | 8GB | Muito Boa | MÃ©dio |
| `mistral:7b` | 4.1GB | 8GB | Muito Boa | MÃ©dio |
| `gemma2:9b` | 5.5GB | 16GB | Excelente | Lento |
| `llama3.1:70b` | 40GB | 64GB | Excelente | Muito Lento |

### HuggingFace

**PrÃ³s:**
- âœ… Gratuito (com limites)
- âœ… Muitos modelos
- âœ… FÃ¡cil uso

**Contras:**
- âŒ Rate limits
- âŒ Mais lento
- âŒ Requer internet

## ğŸƒ Executando Benchmarks

### Teste RÃ¡pido

```bash
# Testa modelos disponÃ­veis com 3 perguntas
python src/experiments/run_experiments.py --mode quick
```

**SaÃ­da esperada:**
```
ğŸš€ TESTE RÃPIDO - ExperimentaÃ§Ã£o de LLMs
================================================================================

ğŸ“ Perguntas de teste:
   1. O que Ã© Retail Media?
   2. Quais sÃ£o as principais mÃ©tricas de performance?
   3. Como funciona o ACOS no Mercado Livre?

ğŸ” Testando OpenAI...
   âœ“ OpenAI configurado
ğŸ” Testando Ollama...
   âœ“ Ollama configurado

ğŸ¯ Testando 2 modelo(s) em 3 perguntas
================================================================================

ğŸ“Š RELATÃ“RIO DE BENCHMARK
================================================================================

ğŸ¤– OPENAI - gpt-4o-mini
--------------------------------------------------------------------------------
  âš¡ LatÃªncia:    1.25s (Â±0.15s)
  ğŸ“ Tokens:      450 (mÃ©dia)
  ğŸ’° Custo:       $0.0023
  â­ Qualidade:   0.87/1.0
  ğŸ¯ RelevÃ¢ncia:  0.92/1.0

ğŸ¤– OLLAMA - llama3.1:8b
--------------------------------------------------------------------------------
  âš¡ LatÃªncia:    2.10s (Â±0.30s)
  ğŸ“ Tokens:      520 (mÃ©dia)
  ğŸ’° Custo:       $0.0000
  â­ Qualidade:   0.82/1.0
  ğŸ¯ RelevÃ¢ncia:  0.88/1.0

================================================================================
ğŸ† RANKING
--------------------------------------------------------------------------------
  ğŸ¥‡ Melhor Qualidade:        openai - gpt-4o-mini (0.87)
  âš¡ Mais RÃ¡pido:             openai - gpt-4o-mini (1.25s)
  ğŸ’ Melhor Custo-BenefÃ­cio:  ollama - llama3.1:8b
================================================================================
```

### Benchmark Completo

```bash
# Testa todos os modelos com todas as perguntas
python src/experiments/run_experiments.py --mode full
```

Testa:
- OpenAI: gpt-4o-mini, gpt-3.5-turbo
- Ollama: llama3.1:8b, mistral:7b, phi3:mini (se disponÃ­veis)

### Uso ProgramÃ¡tico

```python
from src.experiments.multi_llm import MultiLLMManager
from src.experiments.benchmark import ModelBenchmark
from src.agent.retriever import get_retriever
from src.agent.memory import get_memory
from src.agent import config

# Setup RAG
retriever = get_retriever(str(config.VECTOR_DB_DIR), config.EMBEDDING_MODEL)
memory = get_memory(config.HISTORY_FILE)

# Criar benchmark
benchmark = ModelBenchmark(retriever, memory)

# Adicionar modelos
llm1 = MultiLLMManager.create_llm("openai", "gpt-4o-mini")
benchmark.add_model("openai", "gpt-4o-mini", llm1)

llm2 = MultiLLMManager.create_llm("ollama", "llama3.1:8b")
benchmark.add_model("ollama", "llama3.1:8b", llm2)

# Executar
perguntas = [
    "O que Ã© Retail Media?",
    "Como otimizar campanhas?",
]

results = benchmark.run(perguntas)
benchmark.print_report()

# Salvar resultados
report = benchmark.generate_report()
report.to_csv("meu_benchmark.csv")
```

## ğŸ“Š AnÃ¡lise de Resultados

### Jupyter Notebook

```bash
jupyter lab
# Abrir: notebooks/experimentacao_llms.ipynb
```

O notebook inclui:
- ğŸ“Š GrÃ¡ficos comparativos
- ğŸ“ˆ AnÃ¡lise de trade-offs
- ğŸ§ª Testes interativos
- ğŸ’¾ Export de resultados

### Resultados Salvos

Os benchmarks sÃ£o salvos automaticamente em:
- `data/experiments/benchmark_YYYYMMDD_HHMMSS.json` - Dados completos
- `data/experiments/benchmark_YYYYMMDD_HHMMSS.csv` - Formato tabular

### VisualizaÃ§Ã£o Pandas

```python
import pandas as pd

# Carregar resultados
df = pd.read_csv("data/experiments/benchmark_20241118_153045.csv")

# AnÃ¡lises
print(df.groupby("model_name")["quality_score"].mean())
print(df.groupby("model_name")["latency_seconds"].mean())

# GrÃ¡fico
df.groupby("model_name")["quality_score"].mean().plot(kind="bar")
```

## ğŸ”¬ MLflow Tracking

### Iniciar MLflow UI

```bash
# Iniciar servidor
mlflow ui --port 5000

# Ou via script
python src/experiments/run_experiments.py --mode ui

# Abrir: http://localhost:5000
```

### Recursos do MLflow

**Experiments:**
- Compare mÃºltiplos runs
- Visualize mÃ©tricas
- Filtre e ordene resultados

**Metrics:**
- LatÃªncia mÃ©dia
- Qualidade mÃ©dia
- Custo total
- Tokens usados

**Parameters:**
- Modelo usado
- Temperatura
- Max tokens
- Provider

**Artifacts:**
- Resultados JSON
- Logs de execuÃ§Ã£o
- ConfiguraÃ§Ãµes

### Acessar via Python

```python
from src.mlops.tracking import ExperimentTracker

tracker = ExperimentTracker("melancia-retail-media")

# Ver resumo
tracker.print_summary()

# Buscar melhor modelo
best = tracker.get_best_run(metric="quality_avg")
print(f"Melhor modelo: {best['params.model']}")
```

## ğŸ¯ PrÃ³ximos Passos

### Fase 2: Fine-Tuning

ApÃ³s escolher o melhor modelo, vocÃª pode:
1. Coletar dataset especÃ­fico de Retail Media
2. Fine-tuning com LoRA/QLoRA
3. Avaliar modelo personalizado
4. Deploy em produÃ§Ã£o

### Fase 3: MLOps AvanÃ§ado

- Continuous training
- A/B testing de modelos
- Monitoramento de drift
- Feedback loop de usuÃ¡rios

## ğŸ’¡ Dicas e Boas PrÃ¡ticas

### Performance

- **Ollama**: Use GPU se possÃ­vel (`nvidia-smi` para verificar)
- **OpenAI**: Use batch de perguntas para economizar
- **Cache**: Respostas repetidas sÃ£o automÃ¡ticas (ChromaDB)

### Qualidade

- **Temperature**: 0.3-0.5 para respostas consistentes
- **Max Tokens**: 500-1000 para respostas completas
- **Retriever**: k=3-5 documentos Ã© ideal

### Custo

- **Desenvolvimento**: Use Ollama local
- **ProduÃ§Ã£o**: Compare custo vs qualidade
- **HÃ­brido**: Ollama para preview, OpenAI para final

## ğŸ†˜ Troubleshooting

### Ollama nÃ£o conecta

```bash
# Verificar se estÃ¡ rodando
curl http://localhost:11434/api/tags

# Reiniciar
ollama serve

# Ver logs
journalctl -u ollama -f
```

### Erro de memÃ³ria

```bash
# Usar modelo menor
ollama pull phi3:mini  # 3.8GB vs 4.7GB

# Ou aumentar swap (Linux)
sudo fallocate -l 8G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile
```

### HuggingFace rate limit

- Use Ollama local ao invÃ©s
- Ou aguarde 1 hora
- Ou crie nova conta/token

## ğŸ“š Recursos Adicionais

- [Ollama Documentation](https://github.com/ollama/ollama)
- [HuggingFace Models](https://huggingface.co/models)
- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [LangChain Guide](https://python.langchain.com/docs/get_started/introduction)

---

**QuestÃµes?** Abra uma issue no GitHub ou consulte a documentaÃ§Ã£o!


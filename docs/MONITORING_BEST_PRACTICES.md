# ðŸ“Š Monitoramento de LatÃªncia e Performance - Boas PrÃ¡ticas

## ðŸŽ¯ VisÃ£o Geral

Este documento descreve as melhores prÃ¡ticas para monitorar a performance do MelancIA RAG Agent.

---

## ðŸ“ˆ MÃ©tricas Essenciais

### 1. **LatÃªncia**

**Por que monitorar:**
- ExperiÃªncia do usuÃ¡rio depende diretamente do tempo de resposta
- Identificar degradaÃ§Ã£o de performance
- Comparar providers (Ollama vs OpenAI)

**MÃ©tricas chave:**

| MÃ©trica | O que Ã© | SLO Recomendado | Por que Ã© importante |
|---------|---------|-----------------|---------------------|
| **P50** (Mediana) | 50% dos usuÃ¡rios tÃªm latÃªncia menor que isso | < 3s | ExperiÃªncia tÃ­pica |
| **P95** | 95% dos usuÃ¡rios tÃªm latÃªncia menor que isso | < 5s | ExperiÃªncia da maioria |
| **P99** | 99% dos usuÃ¡rios tÃªm latÃªncia menor que isso | < 10s | Detecta outliers |
| **MÃ©dia** | MÃ©dia aritmÃ©tica | < 4s | TendÃªncia geral |
| **Max** | Pior caso | < 30s | Detecta travamentos |

**âš ï¸ Armadilha comum:** Monitorar apenas a mÃ©dia esconde problemas!
- Se P50 = 2s, P95 = 3s, P99 = 60s â†’ MÃ©dia = 3s (parece OK)
- Mas 1% dos usuÃ¡rios espera 1 minuto! (experiÃªncia ruim)

---

### 2. **Throughput**

- **Queries por segundo** (QPS)
- **Queries por hora** por provider
- **Taxa de sucesso** vs erros

---

### 3. **Qualidade**

- **Feedback positivo/negativo** (ðŸ‘/ðŸ‘Ž)
- **Rating mÃ©dio** (1-5 estrelas)
- **MÃ©tricas automÃ¡ticas**: Faithfulness, Answer Relevancy

---

## ðŸ› ï¸ Como Monitorar

### 1. **Interface Web - EstatÃ­sticas em Tempo Real**

Ao rodar `web_interface_with_eval.py`, clique em "ðŸ”„ Atualizar" no painel lateral para ver:
- LatÃªncia mÃ©dia e por modelo
- DistribuiÃ§Ã£o de providers
- Feedback dos usuÃ¡rios
- Queries lentas

### 2. **Script de Monitoramento Standalone**

```bash
# RelatÃ³rio das Ãºltimas 24h
python src/monitoring/latency_monitor.py

# Ãšltimas 12h
python src/monitoring/latency_monitor.py --hours 12

# Modo watch (atualiza a cada 30s)
python src/monitoring/latency_monitor.py --watch
```

**Output do relatÃ³rio:**
```
ðŸ“Š RELATÃ“RIO DE PERFORMANCE - Ãšltimas 24h
================================================================================

### ðŸŽ¯ OVERVIEW GERAL
Total de queries: 150
LatÃªncia mÃ©dia: 4.23s
P50 (mediana): 3.12s
P95: 6.45s
P99: 12.34s
Min/Max: 1.23s / 15.67s

### âš¡ SLO HEALTH CHECK
âŒ P95 < 5.0s: 6.45s (VIOLATION)
âŒ P99 < 10.0s: 12.34s (VIOLATION)

### ðŸ¤– PERFORMANCE POR PROVIDER
ðŸ¦™ OLLAMA
  Queries: 120
  MÃ©dia: 5.12s
  P50: 4.23s | P95: 8.12s | P99: 14.23s

ðŸ¤– OPENAI
  Queries: 30
  MÃ©dia: 1.89s
  P50: 1.45s | P95: 2.34s | P99: 3.12s
```

### 3. **Acesso Direto ao Banco SQLite**

```bash
# Entrar no SQLite
sqlite3 data/evaluation/interactions.db

# Queries Ãºteis:

# Ver Ãºltimas 10 interaÃ§Ãµes
SELECT timestamp, query, latency_seconds, provider 
FROM interactions 
ORDER BY timestamp DESC 
LIMIT 10;

# Queries mais lentas
SELECT query, latency_seconds, provider, timestamp
FROM interactions
ORDER BY latency_seconds DESC
LIMIT 10;

# LatÃªncia mÃ©dia por provider
SELECT provider, 
       COUNT(*) as total,
       AVG(latency_seconds) as avg_latency,
       MAX(latency_seconds) as max_latency
FROM interactions
GROUP BY provider;
```

---

## ðŸš¨ Alertas e SLOs (Service Level Objectives)

### SLOs Recomendados para ProduÃ§Ã£o:

| MÃ©trica | Target | CrÃ­tico |
|---------|--------|---------|
| P50 | < 3s | > 5s |
| P95 | < 5s | > 10s |
| P99 | < 10s | > 20s |
| Taxa de sucesso | > 99% | < 95% |
| Uptime | > 99.9% | < 99% |

### Como Implementar Alertas:

**Exemplo com script simples:**

```python
# Em produÃ§Ã£o, use Prometheus/Grafana
from src.monitoring import LatencyMonitor

monitor = LatencyMonitor()
stats = monitor.get_latency_percentiles(hours=1)

# Alerta se P95 > 5s na Ãºltima hora
if stats['p95'] > 5.0:
    send_alert(f"âš ï¸ P95 latency too high: {stats['p95']:.2f}s")

# Alerta se Ollama estÃ¡ muito lento
comparison = monitor.get_provider_comparison(hours=1)
if comparison.get('ollama', {}).get('avg', 0) > 10.0:
    send_alert("âš ï¸ Ollama averaging > 10s - consider increasing OpenAI fallback")
```

---

## ðŸ”§ OtimizaÃ§Ãµes Baseadas em MÃ©tricas

### Se P95 > 5s:

1. **Aumentar % de OpenAI:**
   ```bash
   export OLLAMA_PERCENTAGE=0.5  # 50% Ollama, 50% OpenAI
   ```

2. **Reduzir timeout do Ollama:**
   ```python
   # web_interface_with_eval.py linha ~220
   timeout_seconds = 10.0  # De 15s para 10s
   ```

3. **Otimizar retriever:**
   ```python
   # config.py
   RETRIEVER_K = 10  # De 15 para 10 documentos
   ```

### Se Ollama >> OpenAI em latÃªncia:

1. **Verificar recursos do servidor:**
   ```bash
   # CPU/RAM disponÃ­vel?
   htop
   
   # Ollama rodando?
   ollama ps
   ```

2. **Trocar para modelo menor:**
   ```bash
   # De llama3.1:8b (8B parÃ¢metros) para:
   ollama pull phi3:mini  # 3.8B parÃ¢metros, mais rÃ¡pido
   ```

3. **Aumentar fallback para OpenAI:**
   ```bash
   export OLLAMA_PERCENTAGE=0.3  # 30% Ollama, 70% OpenAI
   ```

### Se queries especÃ­ficas sÃ£o lentas:

1. **Implementar cache:**
   ```python
   # Cachear perguntas frequentes
   from functools import lru_cache
   
   @lru_cache(maxsize=100)
   def get_cached_response(query_hash):
       return qa_chain.invoke({"question": query})
   ```

2. **Otimizar chunking:**
   ```python
   # retriever.py
   chunk_size=800,  # De 1000 para 800
   ```

---

## ðŸ“Š Ferramentas de Monitoramento em ProduÃ§Ã£o

### **NÃ­vel 1: Built-in** (Atual)
âœ… SQLite + InteractionLogger  
âœ… Gradio UI com stats  
âœ… Script de relatÃ³rio CLI  

**Bom para:** MVP, testes, poucos usuÃ¡rios

---

### **NÃ­vel 2: BÃ¡sico** (Recomendado para produÃ§Ã£o inicial)
- **Prometheus + Grafana**
  - MÃ©tricas em tempo real
  - Dashboards customizÃ¡veis
  - Alertas automÃ¡ticos

```python
# Adicionar mÃ©tricas Prometheus
from prometheus_client import Counter, Histogram, start_http_server

query_latency = Histogram('query_latency_seconds', 'Query latency')
query_counter = Counter('queries_total', 'Total queries', ['provider'])

@query_latency.time()
def process_query(message):
    # ... cÃ³digo existente ...
    query_counter.labels(provider=provider).inc()
```

---

### **NÃ­vel 3: AvanÃ§ado** (Escala)
- **DataDog / New Relic** - APM completo
- **Sentry** - Error tracking
- **PostHog / Mixpanel** - Analytics de produto
- **LangSmith / LangFuse** - LLM observability especÃ­fica

---

## ðŸ“‹ Checklist de Monitoramento

### DiÃ¡rio:
- [ ] Verificar P95 < 5s
- [ ] Verificar taxa de erro < 1%
- [ ] Revisar feedback negativo

### Semanal:
- [ ] Analisar tendÃªncia de latÃªncia
- [ ] Comparar Ollama vs OpenAI
- [ ] Identificar queries problemÃ¡ticas
- [ ] Revisar custos (API OpenAI)

### Mensal:
- [ ] Otimizar modelos baseado em uso
- [ ] Ajustar SLOs conforme necessÃ¡rio
- [ ] AnÃ¡lise de ROI (custo vs qualidade)

---

## ðŸŽ“ ReferÃªncias e Leitura Adicional

- [Google SRE Book - Monitoring Distributed Systems](https://sre.google/sre-book/monitoring-distributed-systems/)
- [AWS - Best Practices for Monitoring LLM Applications](https://aws.amazon.com/blogs/machine-learning/)
- [LangChain - Production Monitoring](https://python.langchain.com/docs/guides/productionization/monitoring/)
- [OpenAI - Best Practices for Production](https://platform.openai.com/docs/guides/production-best-practices)

---

## ðŸ’¡ Resumo: Por que P50/P95/P99?

**P50 (Mediana)** = ExperiÃªncia tÃ­pica  
**P95** = Garantia de qualidade para a maioria  
**P99** = Detecta problemas raros mas crÃ­ticos  

**MÃ©dia sozinha esconde problemas!**

Exemplo real:
- 99 queries em 2s, 1 query em 200s
- **MÃ©dia**: 4s âŒ (parece OK, mas enganoso)
- **P99**: 200s âœ… (mostra o problema real)

---

**ðŸ‰ MelancIA** - Monitoramento proativo para experiÃªncia excepcional!

